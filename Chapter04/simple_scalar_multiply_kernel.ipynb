{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The PyCUDA SourceModule function\n",
    "- The SourceModule function from PyCUDA to compile raw inline CUDA C code into usable kernels that we can launch from Python.\n",
    "- SourceModule actually compiles code into a CUDA module, this is like a Python module or Windows DLL, only it contains a collection of compiled CUDA code.\n",
    "- Conclusion: Write a kernel in pure CUDA C and launch it to use a specific number of threads on our GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\foonwong\\AppData\\Local\\Temp\\ipykernel_16092\\4201704412.py:19: UserWarning: The CUDA compiler succeeded, but said the following:\n",
      "kernel.cu\n",
      "\n",
      "  ker = SourceModule(\"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does our kernel work correctly? : True\n"
     ]
    }
   ],
   "source": [
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "import numpy as np\n",
    "from pycuda import gpuarray\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "# Use a CUDA kernel with SourceModule\n",
    "# Kernel Function: Multiply a vector by a scalar\n",
    "# 1. Precede with the __global__ keyword to distinguish the function as a kernel to the compiler\n",
    "# 2. Declare a void function (Get output values by passing a pointer to some empty chunk of memory that we pass in as a parameter)\n",
    "# 2a. outvec - output scaled vector, which is a floating-point array pointer\n",
    "# 2b. scalar - represented with a float (not pointer)\n",
    "# 2c. vec - input vector, another floating-point array pointer\n",
    "# 3. Singleton input parameters to a kernel function can be passed in directly from the host without using pointers or allocated device memory.\n",
    "# 3a. Last chapter: Singleton input parameters to a kernel function can be passed in directly from the host without using pointers or allocated device memory.\n",
    "# 3b. Identification of each individual thread is given by the threadIdx value, which we retrieve as follows: int i = threadIdx.x\n",
    "# 3c. threadIdx tells each individual thread its identity, to determine an index for what values should be processed on the input and output data arrays. (This can also be used for assigning particular threads different tasks than others with standard C control flow statements such as if or switch.)\n",
    "# 4. outvec[i] = scalar*vec[i] - perform scalar multiplication in parallel like we did previously\n",
    "ker = SourceModule(\"\"\"\n",
    "__global__ void scalar_multiply_kernel(float *outvec, float scalar, float *vec)\n",
    "{\n",
    "     int i = threadIdx.x;\n",
    "     outvec[i] = scalar*vec[i];\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# PyCUDA's get_function - pull out a reference to compiled kernel function from the CUDA module that just compiled with SourceModule\n",
    "scalar_multiply_gpu = ker.get_function(\"scalar_multiply_kernel\")\n",
    "\n",
    "# Floating-point array of 512 random vals\n",
    "testvec = np.random.randn(512).astype(np.float32)\n",
    "\n",
    "# Copy nto an array in the GPU's global memory using the gpuarray.to_gpu function\n",
    "testvec_gpu = gpuarray.to_gpu(testvec)\n",
    "\n",
    "# Allocate a chunk of empty memory to the GPU's global memory using the gpuarray.empty_like function\n",
    "outvec_gpu = gpuarray.empty_like(testvec_gpu)\n",
    "\n",
    "# Set scalar value as 2 (Scalar is singleton, don't need to copy the val to GPU, have to typecast properly)\n",
    "# Set the num of threads to 512 with the block & grid parameters\n",
    "scalar_multiply_gpu( outvec_gpu, np.float32(2), testvec_gpu, block=(512,1,1), grid=(1,1,1))\n",
    "\n",
    "# Check whether the output matches with the expected output by using the get function of the gpuarray object\n",
    "# COmpare via NumPy's allclose\n",
    "print(\"Does our kernel work correctly? : {}\".format(np.allclose(outvec_gpu.get() , 2*testvec) ))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
